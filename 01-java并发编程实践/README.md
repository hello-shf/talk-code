## java并发编程实践

#### [01 | 可见性、原子性和有序性问题：并发编程Bug的源头](https://time.geekbang.org/column/article/83682)

> 笔记

* 并发编程的三个问题
    * 原子性 -> 一个操作是不可中断的，要么全部执行成功要么全部执行失败。
        * 指令级别语义：CPU单个指令一定是原子性的。
        * java语言语义：java中一个指令不代表是具备原子性的。java指令是对CPU指令的封装。（1 - n）
    * 有序性 -> 程序按照代码顺序有序执行
        * 编译期优化：在java编译期，JVM认为改变指令顺序不会影响结果的场景中（不违反happens-before），会进行编译期的指令重排
        * CPU指令重排：为了解决MESI协议导致的CPU空闲，引入了指令重排机制。大大提高了CPU的利用率
    * 可见性 -> 当前线程对共享变量的修改，对其它线程立即可见
        * JMM语义：在JMM中线程对共享变量的修改对其它线程立即可见。
        * CPU语义：一个内核对L1/l2缓存的M(modify)操作对其它S(share)该变量的内核可见。
            * 可见性问题的根本来源：指令重排导致的CPU指令乱序执行。最终根源
                * Store Buffere
                * Invalidte Queue

> 金句

**在采用一项技术的同时，一定要清楚它带来的问题是什么，以及如何规避**

举个例子，我们为了对系统实施监控，会引入例如pinpoint之类的AMP组件，解决了监控问题
的同时也带来了性能问题，比如对带宽的占用，增加了接口响应的延时等；再比如，微服务
架构是为了解决单体应用灵活性差等问题而出现，同时也带了了架构的复杂度，增加了服务
之间通信，数据隔离等问题。所以，一个技术在解决某个问题的同时可能带来新的问题，这样
我们可能又会为新的问题引入别的技术来处理，这是个不断循环的过程。因此，我们在评估
一项技术的时候，需要充分考虑其负面影响，怎么权衡利弊，实现利益最大化。
CPU --> 三级缓存 --> MESI协议 --> 指令重排

#### [02 | Java内存模型：看Java如何解决可见性和有序性问题](https://time.geekbang.org/column/article/84017)

> 笔记

* java内存模型
    * JMM是JVM兼容不同的CPU架构的基础。为了屏蔽底层硬件的差异，向开发者提供统一的接口，故诞生了JMM
    * **JMM只是规范**，**JMM只是规范**，**JMM只是规范**
    * JVM对JMM的实现，才是常见的堆、栈、方法区等一些耳熟能详的名词
* 可见性、有序性的根本解决方案
    * 程序员：对CPU缓存、编译器等按需禁用缓存以及编译优化
        * 方法：volatile/synchronized/final
            * 以上三种方法是java提供给程序员“按需”禁止缓存及编译优化的手段。
    * JVM：happens-before原则
    在JVM可预见的场景中禁止CPU缓存、编译器优化
        * 程序次序规则
            * 在一个线程中，前面的操作总是对后面操作可见
        * 锁定规则
            * 一个unlock操作先行发生于后面对这个锁的lock操作（先释放，才能加锁）        
        * 传递性规则
            * **A happens-before B B happens-before C 则 A happens-before C** （以前理解不到位）
            ```java
            class VolatileExample {
              int x = 0;
              volatile boolean v = false;
              public void writer() {
                x = 42;
                v = true;
              }
              public void reader() {
                if (v == true) {
                  // 这里x会是多少呢？
                }
              }
            }
            ```
        * 线程start规则
            * start前的操作，总是对被start的操作可见。它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。
            ```java
            Thread B = new Thread(()->{
              // 主线程调用B.start()之前
              // 所有对共享变量的修改，此处皆可见
              // 此例中，var==77
            });
            // 此处对共享变量var修改
            var = 77;
            // 主线程启动子线程
            B.start();
            ```
        * 线程 join() 规则
            * 这条是关于线程等待的。它是指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），
            当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作。
            ```java
            Thread B = new Thread(()->{
              // 此处对共享变量var修改
              var = 66;
            });
            // 例如此处对共享变量修改，
            // 则这个修改结果对线程B可见
            // 主线程启动子线程
            B.start();
            B.join()
            // 子线程所有对共享变量的修改
            // 在主线程调用B.join()之后皆可见
            // 此例中，var==66
            ```

> 理解

* 文中的禁用CPU缓存，更深层次的理解见
    * store buffer
    * Invalidate Queue
* volatile/synchronized/final等是java提供给程序员禁止指令重排和禁用缓存的工具
    * CPU为了提高利用率需要指令重排，但是在一些场景中指令重排会导致一些意想不到的错误。这时候需要程序员来发现问题并给出了解决问题的手段
* 重点理解JMM是一种规范、不能混淆JVM对JMM的实现     

#### [03 | 互斥锁（上）：解决原子性问题](https://time.geekbang.org/column/article/84344)

> 笔记

* 原子性问题到底该如何解决呢
    * 原子性问题的源头是线程切换，如果能够禁用线程切换那不就能解决这个问题了吗？而操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。
    * 同一时刻只有一个线程执行”这个条件非常重要，我们称之为互斥。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。
* synchronized
    * synchronized属于重量级锁，性能不高，在锁竞争激烈的场所不建议使用
    * synchronized好处在于简单易用，绝对不会unlock
* 锁和受保护资源的关系
    * 受保护资源和锁之间的关联关系是 N:1 的关系

> 重点

* synchronized锁膨胀过程
* synchronized 对象头 monitor
* long类型的并发读写问题（long64位 -- 32位操作系统）

> 金句

单核时代通过控制线程的切花就可以保证原子性，但是在多核时代，单纯的控制线程切换是无法保证原子性的，需要通过锁的互斥来
保证高并发场景下的原子性。

#### [04 | 互斥锁（下）：如何用一把锁保护多个资源](https://time.geekbang.org/column/article/84601)

> 笔记

* 保护没有关联关系的多个资源
    * 用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫细粒度锁
* 保护有关联关系的多个资源
    * 锁能覆盖所有受保护资源
    * 对象锁无法解决这个问题，因为会产生，我家的锁锁住别人家的资源的情况
    * 正确姿势是采用**类锁**（性能有待优化）

> 理解

* 以前没考虑过也没遇到过 同一把锁管理多个资源的情况，以后在用锁的场景需要注意。


#### [05 | 一不小心就死锁了，怎么办](https://time.geekbang.org/column/article/85001)

>笔记

* 死锁的专业定义
    一组线程因为竞争共享资源而陷入互相等待，导致“永久”阻塞的现象。
    ```java
    class Account {
      private int balance;
      // 转账
      void transfer(Account target, int amt){
        // 锁定转出账户
        synchronized(this){     //①
          // 锁定转入账户
          synchronized(target){ //②
            if (this.balance > amt) {
              this.balance -= amt;
              target.balance += amt;
            }
          }
        }
      } 
    }
    ```
* 在现实中寻找答案
    我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账
    * 文件架上恰好有转出账本和转入账本，那就同时拿走；
    * 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来；
    * 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来。
    死锁产生
    同一时刻A柜员拿到了入账账本，B柜员拿到了出账账本，A等待出账账本，B等待入账账本。AB柜员就会陷入“永久”等待。这就是死锁。
* 粗粒度锁
    解决上述问题，可以采用粗粒度锁，也就是类锁，但是类锁带来的是性能问题。
* 细粒度锁
    * 优点：使用细粒度锁可以提高并行度，是性能优化的有效手段。
    * 风险：机会和风险是并存的。细粒度锁可能导致死锁。
* 如何预防死锁
    解决死锁最好的办法是预防死锁，将其扼杀在摇篮里。
    * 产生死锁的四个条件
        * 互斥，共享资源X和Y只能被一个线程占用
        * 占有且等待，线程T1占有X资源，在等待资源Y的同时，不释放资源X。
        * 不可抢占，其他线程不能强行抢占线程T1占有的资源
        * 循环等待，线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源，就是循环等待
    * 解决死锁的思路就很简单了，就是破坏以上一个条件就不会造成死锁
        * 破坏占用且等待条件：一次性申请所有的资源
            * example：不允许柜员直接在文件架上拿账本，而是增加管理员，柜员拿账本需要通过管理员来审核。比如，A柜员需要拿进账
            管理员发现文件架上没有出账账本，所以不允许柜员只拿进账账本。这样就解决了占用且等待问题。
        * 破坏不可抢占条件：核心是要能够主动释放它占有的资源
            * 这一点 synchronized 是做不到的。因为synchronized一旦申请不到资源就会进入阻塞状态
        进入阻塞态就以为什么也干不了，也释放不了线程占用的资源。
            * ReetrentLock 可以解决这个问题
        * 破坏循环等待条件：对资源排序，然后按序申请资源
            * 我们假设每个账户都有不同的属性 id，这个 id 可以作为排序字段，申请的时候，我们可以按照从小到大的顺序来申请
            ```java
            class Account {
              private int id;
              private int balance;
              // 转账
              void transfer(Account target, int amt){
                Account left = this;        //①
                Account right = target;    //②
                if (this.id > target.id) { //③
                  left = target;           //④
                  right = this;            //⑤
                }                          //⑥
                // 锁定序号小的账户
                synchronized(left){
                  // 锁定序号大的账户
                  synchronized(right){ 
                    if (this.balance > amt){
                      this.balance -= amt;
                      target.balance += amt;
                    }
                  }
                }
              } 
            }
            ```

> 金句

当我们在编程世界里遇到问题时，应不局限于当下，可以换个思路，向现实世界要答案，利用现实世界的模型来构思解决方案，
这样往往能够让我们的方案更容易理解，也更能够看清楚问题的本质。

用细粒度锁来锁定多个资源时，要注意死锁的问题。这个就需要你能把它强化为一个思维定势，遇到这种场景，
马上想到可能存在死锁问题。当你知道风险之后，才有机会谈如何预防和避免，因此，识别出风险很重要

我们在选择具体方案的时候，还需要评估一下操作成本，从中选择一个成本最低的方案。

> 收获

while(true)循环是不是应该有个timeout，避免一直阻塞下去？
加超时在项目中非常实用。


#### [06 | 用“等待-通知”机制优化循环等待](https://time.geekbang.org/column/article/85241)

>笔记

* 问题：05中破坏占用且等待条件，while循环会浪费CPU资源
    ```java
    // 一次性申请转出账户和转入账户，直到成功
    while(!actr.apply(this, target)){...};
    ```
    当并发冲突增加，可能上述while循环会循环上万次，浪费CPU资源
* 方案：等待-通知机制
    * 05中解决占用且等待条件，其实根本原因在于所有线程都在盲目申请，而不是等到“机会”合适的时候再申请。所谓来得早不如来得巧
    * 使用 synchronized, wait(), notify(), notifyAll()实现等待-通知机制
        * **这个等待队列和互斥锁是一对一的关系，每个互斥锁都有自己独立的等待队列**
        * notify() 只能保证在通知时间点，条件是满足的。而被通知线程的执行时间点和通知的时间点基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）
```java
//单例
class Allocator {
  private List<Object> als;
  // 一次性申请所有资源
  synchronized void apply(
    Object from, Object to){
    // 经典写法 范式
    while(als.contains(from) ||
         als.contains(to)){
      try{
        wait();
      }catch(Exception e){
      }   
    } 
    als.add(from);
    als.add(to);  
  }
  // 归还资源
  synchronized void free(
    Object from, Object to){
    als.remove(from);
    als.remove(to);
    notifyAll();
  }
}
//测试方法
public class Test{
    public void test(){
        //加锁
        allocator.apply(from, to);
        //TODO ...
        //释放锁
        allocator.free();
    }
}
```

> 收获
* 尽量使用notifyAll
    * notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。从感觉上来讲，应该是 notify() 更好一些，因为即便通知所有线程，也只有一个线程能够进入临界区。但那所谓的感觉往往都蕴藏着风险，实际上使用 notify() 也很有风险，它的风险在于可能导致某些线程永远不会被通知到。
    假设我们有资源 A、B、C、D，线程 1 申请到了 AB，线程 2 申请到了 CD，此时线程 3 申请 AB，会进入等待队列（AB 分配给线程 1，线程 3 要求的条件不满足），线程 4 申请 CD 也会进入等待队列。我们再假设之后线程 1 归还了资源 AB，如果使用 notify() 来通知等待队列中的线程，有可能被通知的是线程 4，但线程 4 申请的是 CD，所以此时线程 4 还是会继续等待，而真正该唤醒的线程 3 就再也没有机会被唤醒了。所以除非经过深思熟虑，否则尽量使用 notifyAll()。
![06-2](https://github.com/hello-shf/talk-code/blob/master/images/06-2.png?raw=true)
notify工作原理图
* 每个互斥锁都有各自独立的等待池
![06-1](https://github.com/hello-shf/talk-code/blob/master/images/06-1.png?raw=true)
* wait和sleep的区别
wait()方法与sleep()方法的不同之处在于，wait()方法会释放对象的“锁标志”。当调用某一对象的wait()方法后，会使当前线程暂停执行，并将当前线程放入对象等待池中，直到调用了notify()方法后，将从对象等待池中移出任意一个线程并放入锁标志等待池中，只有锁标志等待池中的线程可以获取锁标志，它们随时准备争夺锁的拥有权。当调用了某个对象的notifyAll()方法，会将对象等待池中的所有线程都移动到该对象的锁标志等待池。
sleep()方法需要指定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。但是sleep()方法不会释放“锁标志”，也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。
    * wait释放锁
    * sleep不释放锁

#### [07 | 安全性、活跃性以及性能问题](https://time.geekbang.org/column/article/85702)

> 笔记

* 并发编程的问题
    * 微观上：原子性、可见性、有序性
    * 宏观上：安全性、活跃性、性能
* 安全性问题
    * 理论知识
        * 什么是线程安全？本质上就是正确性：程序按照我们的期望执行
        * 理论上线程安全的程序就是要避免原子性、可见性、有序性问题
        * 需要着重的关注线程安全性的场景：存在**共享数据**并且该数据会发生变化，通俗的讲就是多个线程同时读写同一个数据
    * 数据竞争：当多个线程同时修改一个共享数据时，导致的并发bug（其实就是线程安全性）
    ```java
    public class Test {
      private long count = 0;
      void add10K() {
        int idx = 0;
        while(idx++ < 10000) {
          count += 1;
        }
      }
    }
    ```
    * 竞态条件：指的是线程执行的结果依赖线程执行的顺序
    ```
    public class Test {
      private long count = 0;
      synchronized long get(){
        return count；
      }
      synchronized void set(long v){
        count = v;
      } 
      void add10K() {
        int idx = 0;
        while(idx++ < 10000) {
          set(get()+1) //当两个线程同时运行到get()方法时，get()方法先后（有sync锁）0，count结果为1。当先后执行时，count结果为2     
        }
      }
    }
    ```
    * 解决方案 -- 互斥（锁）
        CPU 提供了相关的互斥指令，操作系统、编程语言也会提供相关的 API。从逻辑上来看，我们可以统一归为：锁
* 活跃性问题
    所谓活跃性问题，指的是某个操作无法执行下去。我们常见的“死锁”就是一种典型的活跃性问题，当然除了死锁外，还有两种情况，分别是“活锁”和“饥饿”
    * 活锁：互相“谦让”的例子。线程因为总是同时的进行竞争而导致的互相等待的现象。
        * 解决方案：让线程等待一个随机的时间。避免“同时”即可
    * 死锁：一组线程线程因为竞争共享数据而陷入永久性等待，导致线程“永久”的阻塞。
        * 解决方案：破坏四个条件即可：互斥、占用且等待、不可抢占、循环等待
    * 饥饿：所谓“饥饿”指的是线程因为无法访问所需资源而无法执行下去的情况
        * 解决方案
            * 公平的分配资源
            * 保证资源充足
            * 避免线程长时间持有锁
                * 公平锁，先来先得
 * 性能问题
    * 尽量采用无锁方式 **乐观锁(CAS)** **本地化存储（ThreadLocal）** **copy-on-write**
    * 尽量减少线程持有锁的时间
    * 优化锁粒度 **联想1.8前后ConcurrentHashMap的锁设计**
 > 总结
 
 * 安全性方面注意**数据竞争** **竞态条件**问题
 * 活跃性方面注意**死锁** **活锁** **饥饿**等问题
 * 性能方面尽量采用无锁CAS，优化锁粒度，减少锁持有时间




